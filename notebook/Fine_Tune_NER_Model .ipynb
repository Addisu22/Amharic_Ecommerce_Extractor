{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7052285b",
   "metadata": {},
   "source": [
    "# Task 3: Fine Tune NER Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a57bfbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers datasets seqeval accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec31ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns   \n",
    "sys.path.append(os.path.abspath(\"../scripts\"))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad289fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "772fe7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll(path):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        words = []\n",
    "        tags = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if words:\n",
    "                    sentences.append(words)\n",
    "                    labels.append(tags)\n",
    "                    words = []\n",
    "                    tags = []\n",
    "            else:\n",
    "                splits = line.split()\n",
    "                if len(splits) >= 2:\n",
    "                    words.append(splits[0])\n",
    "                    tags.append(splits[1])\n",
    "        # Catch last sentence if no trailing newline\n",
    "        if words:\n",
    "            sentences.append(words)\n",
    "            labels.append(tags)\n",
    "    return pd.DataFrame({'tokens': sentences, 'ner_tags': labels})\n",
    "\n",
    "df = read_conll(\"labeled_data.conll\")\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f90590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['ፎርኤቨር', 'ብራይት፦', 'ለጥርስዎ', 'ጥንካሬ', 'ፅዳት', 'እና', 'ንጣት', 'በአንድ', 'የያዘ', 'ከሬት', 'እና', 'ማር', 'የተቀመመ', 'የ', 'ምርት', 'ነው'], 'ner_tags': ['O', 'B-Product', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Product', 'O', 'B-Product', 'O', 'O', 'B-Product', 'O']}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b24872d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f3b2f268684c73988fa9156069c8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e98025b9ee4f2a89fa82a3a27e75cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e2317d331f429db87c7b1891632695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d47f0f077c4d90b12f89a56c5ad972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "label_list = ['O', 'B-Product', 'I-Product', 'B-LOC', 'I-LOC', 'B-PRICE', 'I-PRICE']\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38354d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(example):\n",
    "    tokenized_inputs = tokenizer(example[\"tokens\"], is_split_into_words=True, truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "    labels = []\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "    previous_word_idx = None\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            labels.append(-100)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            labels.append(label_to_id[example[\"ner_tags\"][word_idx]])\n",
    "        else:\n",
    "            # Inside word piece: only keep I-... if applicable\n",
    "            label = example[\"ner_tags\"][word_idx]\n",
    "            labels.append(label_to_id[label] if label.startswith(\"I-\") else -100)\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47afac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_dataset = custom_dataset.map(tokenize_and_align_labels, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e192ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_dataset[0].keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
